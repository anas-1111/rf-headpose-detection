# Head Pose Estimation API

This project provides a **Head Pose Estimation pipeline** using: -
**Mediapipe Face Mesh** (for facial landmarks detection)\
- **Random Forest models** (trained for pitch, yaw, and roll prediction)\
- **FastAPI** (for serving predictions as an API)\
- **OpenCV** (for visualization and processing images/videos)

The system predicts **pitch, yaw, and roll** angles from images or videos, and draws the 3D axis on the detected face.

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    .
    â”œâ”€â”€ models/                      # Trained Random Forest models
    â”‚   â”œâ”€â”€ rf_pitch_model.pkl
    â”‚   â”œâ”€â”€ rf_yaw_model.pkl
    â”‚   â””â”€â”€ rf_roll_model.pkl
    â”œâ”€â”€ api.py                       # FastAPI server with prediction endpoints
    â”œâ”€â”€ notebook.ipynb               # Colab notebook (data preprocessing + training)
    â”œâ”€â”€ Dockerfile                   # Docker configuration file
    â”œâ”€â”€ docker-compose.yml           # Docker Compose file
    â””â”€â”€ README.md                    # Documentation

------------------------------------------------------------------------

## âš™ï¸ Features

-   Supports both **images** and **videos**
-   Runs **face landmark detection** using Mediapipe
-   Extracts selected landmarks for prediction
-   Predicts head pose angles using **Random Forest models**
-   Annotates the image/video with **3D pose axes**
-   Exposes a **FastAPI endpoint** for easy integration

------------------------------------------------------------------------

## ğŸ“Š Models

The models were trained in a **Google Colab notebook** using:  
- **Dataset:** [AFLW2000-3D](https://wywu.github.io/projects/AFLW2000/AFLW2000.html)  
- **Algorithm:** Random Forest (scikit-learn)  
- **Features:** Selected facial landmarks indices for each angle (pitch, yaw, roll)  

Trained models are saved as `.pkl` files:  
- `rf_pitch_model.pkl`  
- `rf_yaw_model.pkl`  
- `rf_roll_model.pkl`  

------------------------------------------------------------------------

## ğŸš€ API Usage

### 1. Install dependencies

``` bash
pip install fastapi uvicorn opencv-python mediapipe scikit-learn joblib
```

### 2. Run FastAPI server

``` bash
uvicorn api:app --reload
```

### 3. Send a request

POST request with the file path:

``` json
{
  "path": "C:/Users/Anas/test_image.jpg"
}
```

### 4. Example Response

``` json
{
  "file_type": "image",
  "input_path": "C:/Users/Anas/test_image.jpg",
  "output_path": "C:/Users/Anas/test_image_predicted.jpg",
  "prediction": {
    "pitch": -8.21,
    "yaw": 3.44,
    "roll": 1.09
  }
}
```

For videos, the response will include the processed video path.

------------------------------------------------------------------------

## ğŸ–¼ï¸ Visualization

-   Red axis â†’ **X direction**  
-   Green axis â†’ **Y direction**  
-   Blue axis â†’ **Z direction**  

------------------------------------------------------------------------

## ğŸ“’ Colab Notebook

The Colab notebook includes:  
- Loading dataset (`AFLW2000-3D`)  
- Extracting facial landmarks  
- Preprocessing & normalization  
- Feature selection  
- Training Random Forest models  
- Saving `.pkl` models for API usage  

------------------------------------------------------------------------

## ğŸ”§ Requirements

-   Python 3.8+  
-   FastAPI  
-   Uvicorn  
-   OpenCV  
-   Mediapipe  
-   Scikit-learn  
-   Joblib  
-   NumPy  

Install everything with:

``` bash
pip install -r requirements.txt
```

------------------------------------------------------------------------

## ğŸ³ Docker Support

You can containerize the project using Docker.  

### 1. Dockerfile

```dockerfile
# Base image
FROM python:3.9-slim

# Set working directory
WORKDIR /app

# Copy requirements if available
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the entire project
COPY . .

# Expose FastAPI default port
EXPOSE 8000

# Run the FastAPI app with Uvicorn
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Build the Docker image

```bash
docker build -t headpose-api .
```

### 3. Run the container

```bash
docker run -p 8000:8000 headpose-api
```

Now the API will be available at:  
ğŸ‘‰ `http://localhost:8000/docs`

------------------------------------------------------------------------

## âš¡ Docker Compose

For easier management, you can use **docker-compose**.

### 1. docker-compose.yml

```yaml
version: "3.8"

services:
  headpose-api:
    build: .
    container_name: headpose_api_container
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    restart: unless-stopped
```

### 2. Run with Compose

```bash
docker-compose up --build
```

This will build the image (if not already built) and start the container automatically.

### 3. Stop the container

```bash
docker-compose down
```

------------------------------------------------------------------------

## ğŸ“Œ Notes

-   Make sure the models (`.pkl`) are placed in the correct path (update in `api.py` if needed).  
-   Works best with **frontal face images/videos**.  
-   Default supported formats:  
    -   Images: `.jpg, .jpeg, .png, .bmp`  
    -   Videos: `.mp4, .avi, .mov, .mkv`  

------------------------------------------------------------------------

## ğŸ“ License

This project is open-source and available under the MIT License.
